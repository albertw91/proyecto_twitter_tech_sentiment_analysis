{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffdc3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import *\n",
    "import json\n",
    "\n",
    "import random\n",
    "random.seed(10)\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Ejemplo con Stack de RNNs\n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, LSTM, SpatialDropout1D\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score #son metricas - area debajo de la curva roc\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c383fe",
   "metadata": {},
   "source": [
    "### Lectura del archivo de tweets ingestados y etiquetados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f820ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>funcionality</th>\n",
       "      <th>client_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:55:56 +0000 2022</td>\n",
       "      <td>EdgarcueroO</td>\n",
       "      <td>¡Disfruta conmigo de llamadas gratis en @Dingt...</td>\n",
       "      <td>5006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:51:30 +0000 2022</td>\n",
       "      <td>gilcuate</td>\n",
       "      <td>RT @IvanNavaMx: Ayudanos a vender 10 boletos d...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:45:56 +0000 2022</td>\n",
       "      <td>ilovminnie_</td>\n",
       "      <td>me cambie a Huawei y ahora no se cómo entrar a...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:14:19 +0000 2022</td>\n",
       "      <td>alexander_tdf</td>\n",
       "      <td>RT @Lauriita18_: NECESITO VUESTRA AYUDA:  Que ...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:06:54 +0000 2022</td>\n",
       "      <td>pablo_calva</td>\n",
       "      <td>@jere_cob24 @HuaweiMobileMx Yo no :( aún sigo ...</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 00:30:12 +0000 2022</td>\n",
       "      <td>Zavala_Ra</td>\n",
       "      <td>Huawei podría aportar a la educación superior ...</td>\n",
       "      <td>7006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 00:28:08 +0000 2022</td>\n",
       "      <td>coosti_b</td>\n",
       "      <td>será este el fin del huawei GW?</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Mon Jun 13 23:53:43 +0000 2022</td>\n",
       "      <td>eveemtz_</td>\n",
       "      <td>@MAULvc7 Me resistiré lo mas que pueda, hasta ...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Mon Jun 13 23:46:33 +0000 2022</td>\n",
       "      <td>blogyarq</td>\n",
       "      <td>@MAULvc7 Es que amo Huawei, tengo el p30 lite ...</td>\n",
       "      <td>70643</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Mon Jun 13 23:44:29 +0000 2022</td>\n",
       "      <td>blogydeco</td>\n",
       "      <td>En estos momentos odio a Huawei??</td>\n",
       "      <td>14568</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_str                      created_at    screen_name  \\\n",
       "0  153653000000000  Tue Jun 14 01:55:56 +0000 2022    EdgarcueroO   \n",
       "1  153653000000000  Tue Jun 14 01:51:30 +0000 2022       gilcuate   \n",
       "2  153653000000000  Tue Jun 14 01:45:56 +0000 2022    ilovminnie_   \n",
       "3  153653000000000  Tue Jun 14 01:14:19 +0000 2022  alexander_tdf   \n",
       "4  153653000000000  Tue Jun 14 01:06:54 +0000 2022    pablo_calva   \n",
       "5  153653000000000  Tue Jun 14 00:30:12 +0000 2022      Zavala_Ra   \n",
       "6  153653000000000  Tue Jun 14 00:28:08 +0000 2022       coosti_b   \n",
       "7  153653000000000  Mon Jun 13 23:53:43 +0000 2022       eveemtz_   \n",
       "8  153653000000000  Mon Jun 13 23:46:33 +0000 2022       blogyarq   \n",
       "9  153653000000000  Mon Jun 13 23:44:29 +0000 2022      blogydeco   \n",
       "\n",
       "                                                text  user_followers  \\\n",
       "0  ¡Disfruta conmigo de llamadas gratis en @Dingt...            5006   \n",
       "1  RT @IvanNavaMx: Ayudanos a vender 10 boletos d...              20   \n",
       "2  me cambie a Huawei y ahora no se cómo entrar a...              51   \n",
       "3  RT @Lauriita18_: NECESITO VUESTRA AYUDA:  Que ...               6   \n",
       "4  @jere_cob24 @HuaweiMobileMx Yo no :( aún sigo ...              39   \n",
       "5  Huawei podría aportar a la educación superior ...            7006   \n",
       "6                    será este el fin del huawei GW?             250   \n",
       "7  @MAULvc7 Me resistiré lo mas que pueda, hasta ...              34   \n",
       "8  @MAULvc7 Es que amo Huawei, tengo el p30 lite ...           70643   \n",
       "9                  En estos momentos odio a Huawei??           14568   \n",
       "\n",
       "   sentiment  funcionality  client_attention  \n",
       "0          0             0                 0  \n",
       "1          0             0                 0  \n",
       "2          0             1                 0  \n",
       "3          0             0                 0  \n",
       "4          0             1                 0  \n",
       "5          0             0                 0  \n",
       "6          0             1                 0  \n",
       "7          0             0                 0  \n",
       "8          1             1                 0  \n",
       "9          0             1                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA = pd.read_csv('tweets_search_etiquetas.csv',delimiter='\\t',encoding='latin-1', dtype = {'id_str': str})\n",
    "corpus_train_esA[\"id_str\"] = corpus_train_esA[\"id_str\"].astype(str).replace(to_replace=\"[.]\", value = \"\", regex=True)\n",
    "corpus_train_esA[\"id_str\"] = corpus_train_esA[\"id_str\"].astype(str).replace(to_replace=\"E\\+\\d{3}\", value = \"\", regex=True)\n",
    "\n",
    "corpus_train_esA.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7359ae4-d01d-458e-8801-223c95e72a3b",
   "metadata": {},
   "source": [
    "### Limpieza en los datos\n",
    "* Cambiar todas las palabras de mayúsculas a minúsculas\n",
    "* Se han eliminado las '@' de @USUARIO con el fin de facilitar el etiquetado morfológico\n",
    "* Quitar los links \n",
    "* Quitar los emojis\n",
    "* Eliminar las stopwords\n",
    "* Se han reemplazado todos los números por el símbolo '0'\n",
    "* Quitar los signos de puntuación y quitar espacios (tabuladores, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef64c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_URL=\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\"\n",
    "\n",
    "def procesar(file, namefile):    \n",
    "    file[file.columns[3]] = [clean_text(i) for i in file[file.columns[3]]]    \n",
    "\n",
    "    sentiment_code_dict = {\"000\":0, \"010\":1, \"001\":2, \"110\":3, \"101\":4, \"011\": 5} \n",
    "    file[\"sentiment_code\"] = file[\"sentiment\"].map(str)  + file[\"funcionality\"].map(str)  + file[\"client_attention\"].map(str) \n",
    "    file[\"sentiment_code\"] = file[\"sentiment_code\"].apply(lambda x: sentiment_code_dict[x])\n",
    "\n",
    "    file.to_csv(namefile, sep=';', encoding='latin-1', index=False)\n",
    "    return file\n",
    "    \n",
    "def clean_text(text):\n",
    "    text = text.lower()   \n",
    "    #text=re.sub(\"@([A-Za-z0-9_]{1,15})\", \"@USUARIO\", text)\n",
    "    text=re.sub(\"@([A-Za-z0-9_]{1,15})\", \"\", text)\n",
    "    text=re.sub(pattern_URL, \"\", text)\n",
    "    \n",
    "    text= remove_emoji(text)\n",
    "    text = re.sub(\"(\\d+)|(rt)|(RT)\", \"\", text)\n",
    "    text = re.sub(\"#\\w+\", \"\", text)\n",
    "    text= remove_stopwords(text)\n",
    "    \n",
    "    # text=re.sub(\"\\d+\", \" \", text)\n",
    "    \n",
    "    text=re.sub(r\" +\", \" \", re.sub(r\"\\t\", \" \", re.sub(r\"\\n+\", \"\\n\", re.sub('(?:[.,\\/!$%?¿?!¡\\^&\\*;:{}=><\\-_`~()”“\"\\'\\|])', \" \",text))))\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):    \n",
    "    nltk.download('stopwords')\n",
    "    stopwords=set(nltk.corpus.stopwords.words(\"spanish\"))\n",
    "    for i in stopwords:\n",
    "        text = re.sub(r\"\\b%s\\b\" % i, \" \", text)\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs                               \n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"\\U00002702-\\U000027B0\"\n",
    "                               \"\\U000024C2-\\U0001F251\"\n",
    "                               \"\\U0001f926-\\U0001f937\"\n",
    "                               \"\\u200d\"\n",
    "                               \"\\u2640-\\u2642\"\n",
    "                               \"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "                               \"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "                               \"\\U0001F600-\\U0001F64F\"\n",
    "                               \"\\U0001F1F2\"\n",
    "                               \"\\U0001F1F4\"\n",
    "                               \"\\U0001F620\"\n",
    "                               \"]+\", flags=re.UNICODE)   \n",
    "    text = emoji_pattern.sub(r'', text) # no emoji\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96e89c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\histe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>funcionality</th>\n",
       "      <th>client_attention</th>\n",
       "      <th>sentiment_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 20 01:55:56 +0000 2022</td>\n",
       "      <td>pruebaTrainDummy</td>\n",
       "      <td>colores fotos huawei estan saturados malos</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 20 01:55:56 +0000 2022</td>\n",
       "      <td>pruebaTrainDummy</td>\n",
       "      <td>contento huawei colores estan saturados</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>155237976078913</td>\n",
       "      <td>Wed Jul 27 19:45:51 +0000 2022</td>\n",
       "      <td>unamushasha</td>\n",
       "      <td>si huawei varian datos ejemplo dice dormi xd</td>\n",
       "      <td>2088</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>15523789805773</td>\n",
       "      <td>Wed Jul 27 19:42:45 +0000 2022</td>\n",
       "      <td>Andre_Villalba</td>\n",
       "      <td>buen teléfono huawei android malo so propietar...</td>\n",
       "      <td>358</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>155237713161064</td>\n",
       "      <td>Wed Jul 27 19:35:24 +0000 2022</td>\n",
       "      <td>loboalonsotegui</td>\n",
       "      <td>llevo huawei pesar fallos mu tontos ahí sigue ...</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id_str                      created_at       screen_name  \\\n",
       "311  153653000000000  Tue Jun 20 01:55:56 +0000 2022  pruebaTrainDummy   \n",
       "312  153653000000000  Tue Jun 20 01:55:56 +0000 2022  pruebaTrainDummy   \n",
       "313  155237976078913  Wed Jul 27 19:45:51 +0000 2022       unamushasha   \n",
       "314   15523789805773  Wed Jul 27 19:42:45 +0000 2022    Andre_Villalba   \n",
       "315  155237713161064  Wed Jul 27 19:35:24 +0000 2022   loboalonsotegui   \n",
       "\n",
       "                                                  text  user_followers  \\\n",
       "311         colores fotos huawei estan saturados malos               1   \n",
       "312            contento huawei colores estan saturados               1   \n",
       "313       si huawei varian datos ejemplo dice dormi xd            2088   \n",
       "314  buen teléfono huawei android malo so propietar...             358   \n",
       "315  llevo huawei pesar fallos mu tontos ahí sigue ...             132   \n",
       "\n",
       "     sentiment  funcionality  client_attention  sentiment_code  \n",
       "311          0             1                 0               1  \n",
       "312          0             1                 0               1  \n",
       "313          0             1                 1               5  \n",
       "314          1             1                 0               3  \n",
       "315          1             1                 0               3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA = procesar(corpus_train_esA, \"tweets_search_etiquetas_clean.csv\")\n",
    "corpus_train_esA.tail()\n",
    "#corpus_train_esA = pd.read_csv(\"tweets_search_etiquetas_clean.csv\", sep = \";\", encoding = \"latin-1\")\n",
    "#corpus_train_esA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1d7ceb",
   "metadata": {},
   "source": [
    "### Particionamiento de los datos en conjunto de entrenamiento y conjunto de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2732e70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>funcionality</th>\n",
       "      <th>client_attention</th>\n",
       "      <th>sentiment_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>153681198832356</td>\n",
       "      <td>Tue Jun 14 20:45:05 +0000 2022</td>\n",
       "      <td>_hidalgovv</td>\n",
       "      <td>sacaba lindas fotos luna huawei</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Mon Jun 13 13:17:35 +0000 2022</td>\n",
       "      <td>Atilaa27</td>\n",
       "      <td>huawei patenta procesador cuántico problemas a...</td>\n",
       "      <td>1916</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 20 01:55:56 +0000 2022</td>\n",
       "      <td>pruebaTrainDummy</td>\n",
       "      <td>camara huawei modo retrato basura recoa siluet...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>153677391512049</td>\n",
       "      <td>Tue Jun 14 18:13:47 +0000 2022</td>\n",
       "      <td>Revolucion_Web</td>\n",
       "      <td>obtén velocidad transmisión tarjetas capacidad...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>153667758493469</td>\n",
       "      <td>Tue Jun 14 11:51:00 +0000 2022</td>\n",
       "      <td>PDD20</td>\n",
       "      <td>hola cualquier huawei lanzado mayo servicios g...</td>\n",
       "      <td>3394</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id_str                      created_at       screen_name  \\\n",
       "90  153681198832356  Tue Jun 14 20:45:05 +0000 2022        _hidalgovv   \n",
       "91  153653000000000  Mon Jun 13 13:17:35 +0000 2022          Atilaa27   \n",
       "92  153653000000000  Tue Jun 20 01:55:56 +0000 2022  pruebaTrainDummy   \n",
       "93  153677391512049  Tue Jun 14 18:13:47 +0000 2022    Revolucion_Web   \n",
       "94  153667758493469  Tue Jun 14 11:51:00 +0000 2022             PDD20   \n",
       "\n",
       "                                                 text  user_followers  \\\n",
       "90                    sacaba lindas fotos luna huawei              64   \n",
       "91  huawei patenta procesador cuántico problemas a...            1916   \n",
       "92  camara huawei modo retrato basura recoa siluet...               1   \n",
       "93  obtén velocidad transmisión tarjetas capacidad...              59   \n",
       "94  hola cualquier huawei lanzado mayo servicios g...            3394   \n",
       "\n",
       "    sentiment  funcionality  client_attention  sentiment_code  \n",
       "90          1             1                 0               3  \n",
       "91          0             0                 0               0  \n",
       "92          0             1                 0               1  \n",
       "93          0             0                 0               0  \n",
       "94          0             1                 0               1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA, corpus_dev_esA = train_test_split(corpus_train_esA, test_size=0.3)\n",
    "\n",
    "corpus_dev_esA.to_csv(\"tweets_search_etiquetas_clean_test.csv\", sep = \";\", encoding = \"latin-1\", index = False)\n",
    "corpus_dev_esA = pd.read_csv(\"tweets_search_etiquetas_clean_test.csv\", sep = \";\", encoding = \"latin-1\")\n",
    "corpus_dev_esA.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dba1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idA = corpus_train_esA[corpus_train_esA.columns[0]]\n",
    "X_train_textA = corpus_train_esA[corpus_train_esA.columns[3]].fillna(' ')\n",
    "#y_train_hsA = corpus_train_esA[[corpus_train_esA.columns[5], corpus_train_esA.columns[6], corpus_train_esA.columns[7]]]\n",
    "y_train_hsA = corpus_train_esA[corpus_train_esA.columns[5]]\n",
    "y_train_hsA = y_train_hsA.values\n",
    "\n",
    "test_idA = corpus_dev_esA[corpus_train_esA.columns[0]]\n",
    "X_test_textA = corpus_dev_esA[corpus_dev_esA.columns[3]].fillna(' ')\n",
    "#y_test_hsA = corpus_dev_esA[[corpus_dev_esA.columns[5], corpus_dev_esA.columns[6], corpus_dev_esA.columns[7]]]\n",
    "y_test_hsA = corpus_dev_esA[corpus_dev_esA.columns[5]]\n",
    "y_test_hsA = y_test_hsA.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36af6f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train_hsA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3796fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(221, 63)\n",
      "(95, 63)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['count_vectorizer.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # CountVectorizer creates a vector with lenght equal to the n of unique words in corupus. 1 indicates\n",
    "# that the word is present\n",
    "cvectorizer = CountVectorizer(\n",
    "    # lowercase=True,\n",
    "    #stop_words=[word.decode('utf-8') for word in nltk.corpus.stopwords.words('spanish')],\n",
    "    #token_pattern=r'\\b\\w+\\b', #selects tokens of 2 or more alphanumeric characters \n",
    "    ngram_range = (3,5),#n-grams de palabras n = 1 a n = 3 (unigramas, bigramas y trigramas)\n",
    "    min_df = 3,#ignorando los términos que tienen una frecuencia de documento estrictamente inferior a 5\n",
    ").fit(X_train_textA) # Identifica las palabras unicas y las coloca en un vector\n",
    "\n",
    "X_train_cvectorized = cvectorizer.transform(X_train_textA).toarray() # para cada palabra unica del corpus, coloca 1 si la palabra aparece en el texto\n",
    "print(X_train_cvectorized.shape)\n",
    "\n",
    "X_test_cvectorized = cvectorizer.transform(X_test_textA).toarray()\n",
    "print(X_test_cvectorized.shape)\n",
    "\n",
    "dump(cvectorizer, 'count_vectorizer.joblib') # Guarda el vectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9210d47-d7c3-434e-ab6c-766174587383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "(95, 63)\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_cvectorized[0]))\n",
    "print(X_test_cvectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f783c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train_cvectorized\n",
    "y_train_hsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549c765a-badd-422b-b41c-bc2df17dbd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'van dos semanas': 60,\n",
       " 'dos semanas sigo': 16,\n",
       " 'semanas sigo esperando': 50,\n",
       " 'sigo esperando respuesta': 53,\n",
       " 'esperando respuesta huawei': 20,\n",
       " 'respuesta huawei prometen': 47,\n",
       " 'huawei prometen cupones': 31,\n",
       " 'prometen cupones pides': 44,\n",
       " 'cupones pides ignoran': 12,\n",
       " 'pides ignoran teléfono': 40,\n",
       " 'van dos semanas sigo': 61,\n",
       " 'dos semanas sigo esperando': 17,\n",
       " 'semanas sigo esperando respuesta': 51,\n",
       " 'sigo esperando respuesta huawei': 54,\n",
       " 'esperando respuesta huawei prometen': 21,\n",
       " 'respuesta huawei prometen cupones': 48,\n",
       " 'huawei prometen cupones pides': 32,\n",
       " 'prometen cupones pides ignoran': 45,\n",
       " 'cupones pides ignoran teléfono': 13,\n",
       " 'van dos semanas sigo esperando': 62,\n",
       " 'dos semanas sigo esperando respuesta': 18,\n",
       " 'semanas sigo esperando respuesta huawei': 52,\n",
       " 'sigo esperando respuesta huawei prometen': 55,\n",
       " 'esperando respuesta huawei prometen cupones': 22,\n",
       " 'respuesta huawei prometen cupones pides': 49,\n",
       " 'huawei prometen cupones pides ignoran': 33,\n",
       " 'prometen cupones pides ignoran teléfono': 46,\n",
       " 'huawei utn firmaron': 34,\n",
       " 'utn firmaron convenio': 57,\n",
       " 'firmaron convenio marco': 23,\n",
       " 'convenio marco colaboración': 8,\n",
       " 'huawei utn firmaron convenio': 35,\n",
       " 'utn firmaron convenio marco': 58,\n",
       " 'firmaron convenio marco colaboración': 24,\n",
       " 'huawei utn firmaron convenio marco': 36,\n",
       " 'utn firmaron convenio marco colaboración': 59,\n",
       " 'huawei nova buena': 27,\n",
       " 'comprar smaphones gama': 6,\n",
       " 'smaphones gama premium': 56,\n",
       " 'comprar smaphones gama premium': 7,\n",
       " 'huawei matepad pro': 26,\n",
       " 'huawei mate pro': 25,\n",
       " 'clientes chiste huawei': 3,\n",
       " 'chiste huawei primero': 0,\n",
       " 'huawei primero ofrecen': 28,\n",
       " 'primero ofrecen cosa': 41,\n",
       " 'ofrecen cosa después': 37,\n",
       " 'cosa después echan': 9,\n",
       " 'después echan atrás': 14,\n",
       " 'echan atrás nota': 19,\n",
       " 'clientes chiste huawei primero': 4,\n",
       " 'chiste huawei primero ofrecen': 1,\n",
       " 'huawei primero ofrecen cosa': 29,\n",
       " 'primero ofrecen cosa después': 42,\n",
       " 'ofrecen cosa después echan': 38,\n",
       " 'cosa después echan atrás': 10,\n",
       " 'después echan atrás nota': 15,\n",
       " 'clientes chiste huawei primero ofrecen': 5,\n",
       " 'chiste huawei primero ofrecen cosa': 2,\n",
       " 'huawei primero ofrecen cosa después': 30,\n",
       " 'primero ofrecen cosa después echan': 43,\n",
       " 'ofrecen cosa después echan atrás': 39,\n",
       " 'cosa después echan atrás nota': 11}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdbd0ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(95, 63)\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print(X_test_cvectorized)\n",
    "print(X_test_cvectorized.shape)\n",
    "print(len(cvectorizer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e01ab278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vocabulary in json format\n",
    "with open(\"cvectorizer_vocabulary_.json\", mode = \"w\", encoding = \"latin-1\", ) as f:\n",
    "    f.write(json.dumps(cvectorizer.vocabulary_, indent = 4, ensure_ascii = False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990a3377",
   "metadata": {},
   "source": [
    "### Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e98f81e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features =  len(cvectorizer.vocabulary_)# or X_train_cvectorized.shape[1] #10000  # tamaño del diccionario de palabras comunes\n",
    "                      # (número de palabras a utilizar)\n",
    "maxlen = X_test_cvectorized.shape[1]  # 67         # longitud máxima de cada secuencia de entrenamiento\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "641c52a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_cvectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2f85d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\histe\\Documents\\formacion\\data_science_IA\\proyecto_twitter_tech_sentiment_analysis\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_12\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m11\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">651</span> (2.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m651\u001b[0m (2.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">651</span> (2.54 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m651\u001b[0m (2.54 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# categorical_crossentropy (cce) produces a one-hot array in the output containing the probable match for each category\n",
    "# when you have only one class per record. This uses softmax, due to this is a multi class problem [0, 1, 0].\n",
    "# sparse_categorical_crossentropy (scce) The vector isn't a one hot, because per record you have one element. [2], pred [.2,.3,.4]\n",
    "# and then this produce a category index of the most likely matching category.\n",
    "# binary_crossentropy: There you have more than one class per record and more than one class. [1,1,0] or simple binary\n",
    "# this loss function uses sigmod, because is a bniary problem\n",
    "\n",
    "model = Sequential()\n",
    "# Capa embedding. Convierte los tokens en vectores densos de dimension fija\n",
    "# input_dim : size of vocavulary (Cada palabra o token se convirtirá en un vector)\n",
    "# output_dim: dimensión del vector al que se mapea\n",
    "# input_length. is the length of tthe tokens by record \n",
    "# output_dim is the size of the embedding vector for each word in the vocabulary.\n",
    "#model.add(Embedding(input_dim = max_features,  output_dim=32, input_length = 15)) # output_dim = 32\n",
    "model.add(Dense(10, activation = \"relu\", input_shape = (len(cvectorizer.vocabulary_),) ))\n",
    "#model.add(SimpleRNN(32, return_sequences=True)) # van despues de embeding\n",
    "#model.add(SimpleRNN(32))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid')) # softmax para multicalse. sigmoid to binary classification\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "\n",
    "model.compile(optimizer='adam', loss = \"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91bd7ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train_cvectorized.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f922d324",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_hsA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43my_train_hsA\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'y_train_hsA' is not defined"
     ]
    }
   ],
   "source": [
    "y_train_hsA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2afcb9b8-f929-4fcc-90bd-2458cfe14608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "6/6 - 0s - 15ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "6/6 - 0s - 12ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "6/6 - 0s - 12ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "6/6 - 0s - 12ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "6/6 - 0s - 12ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "6/6 - 0s - 11ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "6/6 - 0s - 12ms/step - accuracy: 0.6875 - loss: 0.0000e+00 - val_accuracy: 0.7111 - val_loss: 0.0000e+00\n",
      "Tiempo de entrenamiento: 1.1255500316619873\n",
      "loss: 0.00%\n",
      "Training Accuracy: 0.6923\n",
      "Testing Accuracy:  0.6316\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\t Accuracy 0.631578947368421\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tic = time.time()\n",
    "\n",
    "\n",
    "history_stackRNN = model.fit(\n",
    "    X_train_cvectorized, y_train_hsA,\n",
    "    epochs=15,\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('Tiempo de entrenamiento:', time.time()-tic)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train_cvectorized, y_train_hsA, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy)) # accuracy. Exactitud. total de Positives y Falses que son True sobre el total de todo\n",
    "loss, accuracy = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "#plot_history(history)\n",
    "\n",
    "# make predictions\n",
    "testPredict_stackRNN = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_stackRNN.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc81cd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\histe\\Documents\\formacion\\data_science_IA\\proyecto_twitter_tech_sentiment_analysis\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "7/7 - 1s - 139ms/step - accuracy: 0.2036 - loss: 0.9221 - val_accuracy: 0.2000 - val_loss: 0.9013\n",
      "Epoch 2/15\n",
      "7/7 - 0s - 13ms/step - accuracy: 0.2036 - loss: 0.8584 - val_accuracy: 0.2000 - val_loss: 0.8890\n",
      "Epoch 3/15\n",
      "7/7 - 0s - 13ms/step - accuracy: 0.2217 - loss: 0.8453 - val_accuracy: 0.2105 - val_loss: 0.8767\n",
      "Epoch 4/15\n",
      "7/7 - 0s - 13ms/step - accuracy: 0.2217 - loss: 0.8382 - val_accuracy: 0.2105 - val_loss: 0.8646\n",
      "Epoch 5/15\n",
      "7/7 - 0s - 14ms/step - accuracy: 0.2217 - loss: 0.8310 - val_accuracy: 0.2105 - val_loss: 0.8614\n",
      "Epoch 6/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2217 - loss: 0.8289 - val_accuracy: 0.2105 - val_loss: 0.8596\n",
      "Epoch 7/15\n",
      "7/7 - 0s - 13ms/step - accuracy: 0.2217 - loss: 0.8280 - val_accuracy: 0.2105 - val_loss: 0.8579\n",
      "Epoch 8/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2217 - loss: 0.8230 - val_accuracy: 0.2105 - val_loss: 0.8572\n",
      "Epoch 9/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2217 - loss: 0.8218 - val_accuracy: 0.2105 - val_loss: 0.8561\n",
      "Epoch 10/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2217 - loss: 0.8231 - val_accuracy: 0.2105 - val_loss: 0.8550\n",
      "Epoch 11/15\n",
      "7/7 - 0s - 14ms/step - accuracy: 0.2217 - loss: 0.8267 - val_accuracy: 0.2105 - val_loss: 0.8545\n",
      "Epoch 12/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2217 - loss: 0.8278 - val_accuracy: 0.2526 - val_loss: 0.8564\n",
      "Epoch 13/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2353 - loss: 0.8398 - val_accuracy: 0.2526 - val_loss: 0.8619\n",
      "Epoch 14/15\n",
      "7/7 - 0s - 12ms/step - accuracy: 0.2353 - loss: 0.8291 - val_accuracy: 0.2526 - val_loss: 0.8589\n",
      "Epoch 15/15\n",
      "7/7 - 0s - 11ms/step - accuracy: 0.2353 - loss: 0.8291 - val_accuracy: 0.2526 - val_loss: 0.8497\n",
      "Training Accuracy: 0.2353\n",
      "Testing Accuracy:  0.2526\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "\t Accuracy 0.4421052631578947\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = batch_size # 50 #batch_size\n",
    "#maxlen = 15\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_features, \n",
    "                           output_dim = embedding_dim, \n",
    "                           input_length = maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train_cvectorized, y_train_hsA,\n",
    "                    epochs=15,\n",
    "                    verbose=2,\n",
    "                    validation_data=(X_test_cvectorized, y_test_hsA),\n",
    "                    batch_size=batch_size)\n",
    "                    \n",
    "loss, accuracy = model.evaluate(X_train_cvectorized, y_train_hsA, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "#plot_history(history)\n",
    "\n",
    "# make predictions\n",
    "testPredict_stackRNN = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_stackRNN.round()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08bdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d890cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\histe\\Documents\\formacion\\data_science_IA\\proyecto_twitter_tech_sentiment_analysis\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/10\n",
      "7/7 - 2s - 298ms/step - accuracy: 0.2715 - loss: 0.9748\n",
      "Epoch 2/10\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.2036 - loss: 0.9053\n",
      "Epoch 3/10\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.2036 - loss: 0.8858\n",
      "Epoch 4/10\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.2036 - loss: 0.8767\n",
      "Epoch 5/10\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.2081 - loss: 0.8661\n",
      "Epoch 6/10\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.2217 - loss: 0.8633\n",
      "Epoch 7/10\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.2217 - loss: 0.8512\n",
      "Epoch 8/10\n",
      "7/7 - 0s - 23ms/step - accuracy: 0.2217 - loss: 0.8606\n",
      "Epoch 9/10\n",
      "7/7 - 0s - 22ms/step - accuracy: 0.2217 - loss: 0.8556\n",
      "Epoch 10/10\n",
      "7/7 - 0s - 21ms/step - accuracy: 0.2217 - loss: 0.8770\n",
      "Training Accuracy: 0.2036\n",
      "Testing Accuracy:  0.2000\n",
      "WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AE29EE7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 199ms/stepWARNING:tensorflow:6 out of the last 9 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002AE29EE7560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step\n",
      "\t Accuracy 0.18947368421052632\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lstm_out = 98\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim = max_features, output_dim = embedding_dim, input_length = maxlen))\n",
    "#model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n",
    "\n",
    "batch_size = 32\n",
    "model.fit(X_train_cvectorized, y_train_hsA, epochs = 10, batch_size=batch_size, verbose = 2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train_cvectorized, y_train_hsA, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))\n",
    "#plot_history(history)\n",
    "\n",
    "# make predictions\n",
    "testPredict_stackRNN = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_stackRNN.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4148a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('best_keras_network_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efc35d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('[0 0 0]', 105), ('[0 1 0]', 41), ('[1 1 0]', 45), ('[0 0 1]', 14), ('[1 0 1]', 1)])\n"
     ]
    }
   ],
   "source": [
    "input_list = list(map(lambda x: str(x), y_train_hsA.round()))\n",
    "c = Counter( input_list )\n",
    "\n",
    "print( c.items() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f33e0f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dev_esA[\"predict_test\"] = list(map(lambda x: str(x), testPredict_stackRNN.round()))\n",
    "\n",
    "corpus_dev_esA.to_csv(\"tweets_search_etiquetas_clean_test_predict.csv\", sep=\"\\t\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "432abdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 0. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 0. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 0. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 0. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 0. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]',\n",
       " '[0. 1. 0.]']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: str(x), testPredict_stackRNN.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ee28134-d748-4174-9374-db637433df2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "from dash import Dash, html, dcc\n",
    "import plotly.express as px\n",
    "from dash.dependencies import Input, Output\n",
    "import pandas as pd\n",
    "\n",
    "app = Dash(__name__)\n",
    "\n",
    "# assume you have a \"long-form\" data frame\n",
    "# see https://plotly.com/python/px-arguments/ for more options\n",
    "\"\"\"\n",
    "df = pd.DataFrame({\n",
    "    \"Ambito\": [\"funcionamiento\", \"atencion_cliente\", \"atencion_cliente\", \"funcionamiento\", \"funcionamiento\", \"funcionamiento\"],\n",
    "    \"Conteo\": [4, 1, 2, 2, 4, 5],\n",
    "    \"Sentimiento\": [\"Positivo\", \"Negativo\", \"Negativo\", \"Negativo\", \"Negativo\", \"Positivo\"]\n",
    "})\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(children='Hello Dash'),\n",
    "\n",
    "    html.Div(children='''\n",
    "        Analisis de sentimiento\n",
    "    '''),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='live-update-graph'#,\n",
    "        #figure=fig\n",
    "    ),\n",
    "    dcc.Interval(\n",
    "            id='interval-component',\n",
    "            interval=8*1000, # in milliseconds\n",
    "            n_intervals=0\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "# Multiple components can update everytime interval gets fired.\n",
    "@app.callback(Output('live-update-graph', 'figure'),\n",
    "              Input('interval-component', 'n_intervals'))\n",
    "def update_graph_live(n):\n",
    "\n",
    "    df = pd.read_csv(\"stream_tweet_groupby.csv\", sep = \",\", encoding= \"latin-1\", dtype = {'sentiment_code': str})\n",
    "\n",
    "    df[\"sentiment_bin\"] = df[\"sentiment_code\"].apply(lambda x: str(x[0]))\n",
    "    sentiment_dict = {\"0\": \"negativo\", \"1\": \"positivo\"}\n",
    "    df[\"sentiment_bin\"] = df[\"sentiment_bin\"].apply(lambda x: sentiment_dict[x])\n",
    "\n",
    "    fig = px.bar(df, x=\"sentiment_code\", y=\"count\", color =\"sentiment_bin\", barmode=\"group\")\n",
    "    #fig = px.bar(df, x=\"Fruit\", y=\"Amount\", color=\"City\", barmode=\"group\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a706848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab43c559",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'search_or_simulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19408/2404869653.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msearch_or_simulate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSearchOrSimulate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mapi_twitter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStreammerTwitter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mstreammer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSearchOrSimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'search_or_simulate'"
     ]
    }
   ],
   "source": [
    "\n",
    "from search_or_simulate import SearchOrSimulate\n",
    "from api_twitter import StreammerTwitter\n",
    "\n",
    "\n",
    "streammer = SearchOrSimulate()\n",
    "#streammer.simulate_search_streaming(\"tweets_search_2.txt\", True, model_file = \"best_keras_network_model.h5\", cvectorizer_file = \"count_vectorizer.joblib\")\n",
    "#streammer.search_streaming(\"streaming_tweets_search.txt\", False, model_file = \"best_keras_network_model.h5\", cvectorizer_file = \"count_vectorizer.joblib\")\n",
    "streammer.search_30_days_ago()\n",
    "#transformed_tweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0053b66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38773740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
