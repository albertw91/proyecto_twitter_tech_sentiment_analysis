{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffdc3ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import *\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Ejemplo con Stack de RNNs\n",
    "from keras.layers import Embedding, SimpleRNN\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac29c65-ae05-45a1-a710-74cd434985fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79f820ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_esA = pd.read_csv('tweets_search_etiquetas.csv',delimiter='\\t',encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f45b79c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>funcionality</th>\n",
       "      <th>client_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.536530e+14</td>\n",
       "      <td>Tue Jun 14 01:55:56 +0000 2022</td>\n",
       "      <td>EdgarcueroO</td>\n",
       "      <td>¡Disfruta conmigo de llamadas gratis en @Dingt...</td>\n",
       "      <td>5006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.536530e+14</td>\n",
       "      <td>Tue Jun 14 01:51:36 +0000 2022</td>\n",
       "      <td>rincon_tec</td>\n",
       "      <td>#silent #compact ??Tsimak cartera funda para H...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.536530e+14</td>\n",
       "      <td>Tue Jun 14 01:51:33 +0000 2022</td>\n",
       "      <td>gilcuate</td>\n",
       "      <td>RT @IvanNavaMx: Huawei P30 Pro de 256 GB Negro...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.536530e+14</td>\n",
       "      <td>Tue Jun 14 01:51:30 +0000 2022</td>\n",
       "      <td>gilcuate</td>\n",
       "      <td>RT @IvanNavaMx: Ayudanos a vender 10 boletos d...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.536530e+14</td>\n",
       "      <td>Tue Jun 14 01:45:56 +0000 2022</td>\n",
       "      <td>ilovminnie_</td>\n",
       "      <td>me cambie a Huawei y ahora no se cómo entrar a...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_str                      created_at  screen_name  \\\n",
       "0  1.536530e+14  Tue Jun 14 01:55:56 +0000 2022  EdgarcueroO   \n",
       "1  1.536530e+14  Tue Jun 14 01:51:36 +0000 2022   rincon_tec   \n",
       "2  1.536530e+14  Tue Jun 14 01:51:33 +0000 2022     gilcuate   \n",
       "3  1.536530e+14  Tue Jun 14 01:51:30 +0000 2022     gilcuate   \n",
       "4  1.536530e+14  Tue Jun 14 01:45:56 +0000 2022  ilovminnie_   \n",
       "\n",
       "                                                text  user_followers  \\\n",
       "0  ¡Disfruta conmigo de llamadas gratis en @Dingt...            5006   \n",
       "1  #silent #compact ??Tsimak cartera funda para H...              13   \n",
       "2  RT @IvanNavaMx: Huawei P30 Pro de 256 GB Negro...              20   \n",
       "3  RT @IvanNavaMx: Ayudanos a vender 10 boletos d...              20   \n",
       "4  me cambie a Huawei y ahora no se cómo entrar a...              51   \n",
       "\n",
       "   sentiment  funcionality  client_attention  \n",
       "0          0             0                 0  \n",
       "1          0             0                 0  \n",
       "2          0             0                 0  \n",
       "3          0             0                 0  \n",
       "4          0             1                 0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7359ae4-d01d-458e-8801-223c95e72a3b",
   "metadata": {},
   "source": [
    "### Limpieza en los datos\n",
    "* Cambiar todas las palabras de mayúsculas a minúsculas\n",
    "* Se han eliminado las '@' de @USUARIO con el fin de facilitar el etiquetado morfológico\n",
    "* Quitar los links \n",
    "* Quitar los emojis\n",
    "* No Eliminar las stopwords\n",
    "* Se han reemplazado todos los números por el símbolo '0'\n",
    "* Quitar los signos de puntuación y quitar espacios (tabuladores, etc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eef64c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_URL=\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\"\n",
    "\n",
    "def procesar(file, namefile):    \n",
    "    file[file.columns[3]] = [clean_text(i) for i in file[file.columns[3]]]    \n",
    "    file.to_csv(namefile, sep=';', encoding='latin-1', index=False)\n",
    "    return file\n",
    "    \n",
    "def clean_text(text):\n",
    "    text = text.lower()   \n",
    "    #text=re.sub(\"@([A-Za-z0-9_]{1,15})\", \"@USUARIO\", text)\n",
    "    text=re.sub(\"@([A-Za-z0-9_]{1,15})\", \" \", text)\n",
    "    text=re.sub(pattern_URL, \" \", text)\n",
    "    \n",
    "    text= remove_emoji(text)\n",
    "    #text= remove_stopwords(text)\n",
    "    text=re.sub(\"\\d+\", \"0\", text)\n",
    "    # text=re.sub(\"\\d+\", \" \", text)\n",
    "    \n",
    "    text=re.sub(r\" +\", \" \", re.sub(r\"\\t\", \" \", re.sub(r\"\\n+\", \"\\n\", re.sub('(?:[.,\\/!$%?¿?!¡\\^&\\*;:{}=><\\-_`~()”“\"\\'\\|])', \" \",text))))\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):    \n",
    "    stopwords=set(nltk.corpus.stopwords.words(\"spanish\"))\n",
    "    for i in stopwords:\n",
    "        text = re.sub(r\"\\b%s\\b\" % i, \" \", text)\n",
    "    return text\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs                               \n",
    "                               \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               \"\\U00002702-\\U000027B0\"\n",
    "                               \"\\U000024C2-\\U0001F251\"\n",
    "                               \"\\U0001f926-\\U0001f937\"\n",
    "                               \"\\u200d\"\n",
    "                               \"\\u2640-\\u2642\"\n",
    "                               \"\\U0001F1F2-\\U0001F1F4\"  # Macau flag\n",
    "                               \"\\U0001F1E6-\\U0001F1FF\"  # flags\n",
    "                               \"\\U0001F600-\\U0001F64F\"\n",
    "                               \"\\U0001F1F2\"\n",
    "                               \"\\U0001F1F4\"\n",
    "                               \"\\U0001F620\"\n",
    "                               \"]+\", flags=re.UNICODE)   \n",
    "    text = emoji_pattern.sub(r'', text) # no emoji\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e89c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70b57d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_str</th>\n",
       "      <th>created_at</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>text</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>funcionality</th>\n",
       "      <th>client_attention</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:55:56 +0000 2022</td>\n",
       "      <td>EdgarcueroO</td>\n",
       "      <td>disfruta conmigo de llamadas gratis en</td>\n",
       "      <td>5006</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:51:36 +0000 2022</td>\n",
       "      <td>rincon_tec</td>\n",
       "      <td>#silent #compact tsimak cartera funda para hua...</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:51:33 +0000 2022</td>\n",
       "      <td>gilcuate</td>\n",
       "      <td>rt huawei p0 pro de 0 gb negro 0 con su ayuda ...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:51:30 +0000 2022</td>\n",
       "      <td>gilcuate</td>\n",
       "      <td>rt ayudanos a vender 0 boletos de esta rifa po...</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153653000000000</td>\n",
       "      <td>Tue Jun 14 01:45:56 +0000 2022</td>\n",
       "      <td>ilovminnie_</td>\n",
       "      <td>me cambie a huawei y ahora no se cómo entrar a...</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id_str                      created_at  screen_name  \\\n",
       "0  153653000000000  Tue Jun 14 01:55:56 +0000 2022  EdgarcueroO   \n",
       "1  153653000000000  Tue Jun 14 01:51:36 +0000 2022   rincon_tec   \n",
       "2  153653000000000  Tue Jun 14 01:51:33 +0000 2022     gilcuate   \n",
       "3  153653000000000  Tue Jun 14 01:51:30 +0000 2022     gilcuate   \n",
       "4  153653000000000  Tue Jun 14 01:45:56 +0000 2022  ilovminnie_   \n",
       "\n",
       "                                                text  user_followers  \\\n",
       "0             disfruta conmigo de llamadas gratis en            5006   \n",
       "1  #silent #compact tsimak cartera funda para hua...              13   \n",
       "2  rt huawei p0 pro de 0 gb negro 0 con su ayuda ...              20   \n",
       "3  rt ayudanos a vender 0 boletos de esta rifa po...              20   \n",
       "4  me cambie a huawei y ahora no se cómo entrar a...              51   \n",
       "\n",
       "   sentiment  funcionality  client_attention  \n",
       "0          0             0                 0  \n",
       "1          0             0                 0  \n",
       "2          0             0                 0  \n",
       "3          0             0                 0  \n",
       "4          0             1                 0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_train_esA = procesar(corpus_train_esA, \"tweets_search_etiquetas_clean.csv\")\n",
    "corpus_dev_esA = pd.read_csv(\"tweets_search_etiquetas_clean_test.csv\", sep = \";\", encoding = \"latin-1\")\n",
    "corpus_dev_esA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90033d-33fc-44e6-9752-fa0b1e0ee4c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dba1587",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idA = corpus_train_esA[corpus_train_esA.columns[0]]\n",
    "X_train_textA = corpus_train_esA[corpus_train_esA.columns[3]].fillna(' ')\n",
    "y_train_hsA = corpus_train_esA[corpus_train_esA.columns[5]]\n",
    "\n",
    "test_idA = corpus_dev_esA[corpus_train_esA.columns[0]]\n",
    "X_test_textA = corpus_dev_esA[corpus_dev_esA.columns[3]].fillna(' ')\n",
    "y_test_hsA = corpus_dev_esA[corpus_dev_esA.columns[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3796fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(612, 837)\n",
      "(161, 837)\n"
     ]
    }
   ],
   "source": [
    "cvectorizer = CountVectorizer(\n",
    "    # lowercase=True,\n",
    "    #stop_words=[word.decode('utf-8') for word in nltk.corpus.stopwords.words('spanish')],\n",
    "    #token_pattern=r'\\b\\w+\\b', #selects tokens of 2 or more alphanumeric characters \n",
    "    ngram_range=(1,3),#n-grams de palabras n = 1 a n = 3 (unigramas, bigramas y trigramas)\n",
    "    min_df=5,#ignorando los términos que tienen una frecuencia de documento estrictamente inferior a 5\n",
    ").fit(X_train_textA)\n",
    "\n",
    "X_train_cvectorized = cvectorizer.transform(X_train_textA).toarray()\n",
    "print(X_train_cvectorized.shape)\n",
    "\n",
    "X_test_cvectorized = cvectorizer.transform(X_test_textA).toarray()\n",
    "print(X_test_cvectorized.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9210d47-d7c3-434e-ab6c-766174587383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 4}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(X_train_cvectorized[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "549c765a-badd-422b-b41c-bc2df17dbd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cvectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2afcb9b8-f929-4fcc-90bd-2458cfe14608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, None, 32)          320000    \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, None, 32)          2080      \n",
      "                                                                 \n",
      " simple_rnn_3 (SimpleRNN)    (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 324,193\n",
      "Trainable params: 324,193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "4/4 - 6s - loss: 0.6197 - acc: 0.7321 - val_loss: 0.3872 - val_acc: 0.9187 - 6s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "4/4 - 4s - loss: 0.3003 - acc: 0.9591 - val_loss: 0.3103 - val_acc: 0.9187 - 4s/epoch - 961ms/step\n",
      "Epoch 3/15\n",
      "4/4 - 2s - loss: 0.2287 - acc: 0.9591 - val_loss: 0.2886 - val_acc: 0.9187 - 2s/epoch - 548ms/step\n",
      "Epoch 4/15\n",
      "4/4 - 2s - loss: 0.2001 - acc: 0.9591 - val_loss: 0.2825 - val_acc: 0.9187 - 2s/epoch - 613ms/step\n",
      "Epoch 5/15\n",
      "4/4 - 3s - loss: 0.1868 - acc: 0.9591 - val_loss: 0.2820 - val_acc: 0.9187 - 3s/epoch - 709ms/step\n",
      "Epoch 6/15\n",
      "4/4 - 3s - loss: 0.1796 - acc: 0.9591 - val_loss: 0.2840 - val_acc: 0.9187 - 3s/epoch - 794ms/step\n",
      "Epoch 7/15\n",
      "4/4 - 3s - loss: 0.1750 - acc: 0.9591 - val_loss: 0.2874 - val_acc: 0.9187 - 3s/epoch - 851ms/step\n",
      "Epoch 8/15\n",
      "4/4 - 3s - loss: 0.1728 - acc: 0.9591 - val_loss: 0.2910 - val_acc: 0.9187 - 3s/epoch - 681ms/step\n",
      "Epoch 9/15\n",
      "4/4 - 2s - loss: 0.1716 - acc: 0.9591 - val_loss: 0.2929 - val_acc: 0.9187 - 2s/epoch - 538ms/step\n",
      "Epoch 10/15\n",
      "4/4 - 2s - loss: 0.1711 - acc: 0.9591 - val_loss: 0.2955 - val_acc: 0.9187 - 2s/epoch - 538ms/step\n",
      "Epoch 11/15\n",
      "4/4 - 2s - loss: 0.1712 - acc: 0.9591 - val_loss: 0.2961 - val_acc: 0.9187 - 2s/epoch - 526ms/step\n",
      "Epoch 12/15\n",
      "4/4 - 2s - loss: 0.1710 - acc: 0.9591 - val_loss: 0.2961 - val_acc: 0.9187 - 2s/epoch - 585ms/step\n",
      "Epoch 13/15\n",
      "4/4 - 2s - loss: 0.1712 - acc: 0.9591 - val_loss: 0.2987 - val_acc: 0.9187 - 2s/epoch - 546ms/step\n",
      "Epoch 14/15\n",
      "4/4 - 2s - loss: 0.1711 - acc: 0.9591 - val_loss: 0.2971 - val_acc: 0.9187 - 2s/epoch - 526ms/step\n",
      "Epoch 15/15\n",
      "4/4 - 2s - loss: 0.1713 - acc: 0.9591 - val_loss: 0.2995 - val_acc: 0.9187 - 2s/epoch - 507ms/step\n",
      "Tiempo de entrenamiento: 41.48822021484375\n",
      "hola loss: 21.88%\n",
      "hola 2 acc: 94.41%\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7708/1816773271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hola %s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hola 2 %s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hola 3 %s: %.2f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;31m# make predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "max_features = 10000  # tamaño del diccionario de palabras comunes\n",
    "                      # (número de palabras a utilizar)\n",
    "maxlen = X_test_cvectorized.shape[1] #1775         # longitud máxima de cada secuencia \n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "# Capa embedding\n",
    "# input_dim : tamaño del vocabulario\n",
    "# output_dim: dimensión del vector al que se mapea\n",
    "model.add(Embedding(input_dim=max_features, output_dim=32))\n",
    "model.add(SimpleRNN(32, return_sequences=True))\n",
    "model.add(SimpleRNN(32))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(\n",
    "    optimizer='rmsprop', \n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['acc']\n",
    ")\n",
    "\n",
    "tic = time.time()\n",
    "history_stackRNN = model.fit(\n",
    "    X_train_cvectorized, y_train_hsA,\n",
    "    epochs=15,\n",
    "    batch_size=128,\n",
    "    validation_split=0.2,\n",
    "    verbose=2\n",
    ")\n",
    "print('Tiempo de entrenamiento:', time.time()-tic)\n",
    "\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X_test_cvectorized, y_test_hsA, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[0], scores[0]*100))\n",
    "\n",
    "\n",
    "\n",
    "# make predictions\n",
    "testPredict_stackRNN = model.predict(X_test_cvectorized)\n",
    "print('\\t', 'Accuracy', accuracy_score(y_test_hsA, testPredict_stackRNN.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e8bad6-69bd-4ab7-8bdb-db85d9fffaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(testPredict_stackRNN.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee28134-d748-4174-9374-db637433df2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
